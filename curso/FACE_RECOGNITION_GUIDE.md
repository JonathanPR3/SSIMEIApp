# Gu√≠a de Implementaci√≥n - Reconocimiento Facial

## üìã Resumen de la Implementaci√≥n

‚úÖ **COMPLETADO (2025-11-17):** Sistema de reconocimiento facial **completamente integrado con backend FastAPI usando DeepFace/Facenet512**. La app ahora puede:
- Registrar rostros enviando imagen al backend para generar embedding (512 dimensiones)
- Reconocer rostros comparando contra base de datos usando distancia coseno
- Listar rostros registrados de la organizaci√≥n
- Probar reconocimiento facial en tiempo real con c√°mara frontal

## üóÇÔ∏è Estructura de Archivos Creados/Modificados

### Nuevos Archivos (2025-11-17)

1. **`lib/services/face_recognition_api_service.dart`** ‚≠ê NUEVO
   - Servicio REAL conectado al backend FastAPI
   - `registerFace()` - Env√≠a imagen al backend para registro
   - `recognizeFace()` - Reconoce rostro comparando contra BD
   - `listFaces()` - Lista todos los rostros de la organizaci√≥n
   - `deleteFace()` - Elimina rostro
   - `getMyFace()` - Obtiene rostro del usuario actual
   - Incluye manejo de `MediaType.parse()` para content-type correcto

2. **`lib/screens/test_face_recognition_screen.dart`** ‚≠ê NUEVO
   - Pantalla de prueba con preview de c√°mara frontal
   - Captura foto y env√≠a a `/api/v1/faces/recognize`
   - Muestra resultado: reconocido/no reconocido
   - Informaci√≥n detallada: nombre, tipo, confianza, face_id
   - Estados visuales (borde verde si reconoce)

### Archivos Modificados (2025-11-17)

3. **`lib/config/api_config.dart`**
   - Agregados endpoints de reconocimiento facial:
     - `POST /api/v1/faces` - Registrar rostro
     - `GET /api/v1/faces` - Listar rostros
     - `DELETE /api/v1/faces/{id}` - Eliminar rostro
     - `POST /api/v1/faces/recognize` - Reconocer rostro
     - `GET /api/v1/faces/users/{userId}/face` - Rostro de usuario

4. **`lib/screens/face_capture_screen.dart`**
   - Mantiene proceso de captura de 5 im√°genes (UX sin cambios)
   - **Env√≠a SOLO primera imagen al backend** para generar embedding
   - Backend procesa con DeepFace/Facenet512 autom√°ticamente
   - Manejo de errores con dialog para guardar localmente si falla backend
   - Guarda tambi√©n localmente para compatibilidad

5. **`lib/screens/manage_faces_screen.dart`**
   - **Carga rostros desde backend** en lugar de almacenamiento local
   - Toggle `useBackend = true` (usa API real)
   - Soporta ambos tipos de rostros:
     - `registered_user` - Usuario registrado (tiene user_id)
     - `non_user` - Visitante (usa face_metadata con full_name)
   - Manejo correcto de tipos de ID (int backend vs String local)
   - Eliminaci√≥n de rostros v√≠a API

6. **`lib/screens/settings/SettingsScreen.dart`**
   - Agregada nueva opci√≥n en secci√≥n "Rostros"
   - "Probar Reconocimiento Facial" con subt√≠tulo "Modo de prueba"
   - Navegaci√≥n a `TestFaceRecognitionScreen`
   - Modificado `_buildSettingsCard()` para aceptar `subtitle` opcional

## üì∏ ¬øC√≥mo Funciona Actualmente?

### Flujo de Registro de Rostro (Backend Integrado)

1. Usuario abre "Gestionar Rostros" desde Settings
2. Presiona "Registrar Nuevo Rostro"
3. La app captura **5 im√°genes** (UX sin cambios):
   - Paso 1: Rostro centrado
   - Paso 2: Girado a la izquierda
   - Paso 3: Girado a la derecha
   - Paso 4: Sonriendo
   - Paso 5: Expresi√≥n neutral

4. **Backend procesa SOLO la primera imagen:**
   - Se env√≠a a `POST /api/v1/faces` con multipart/form-data
   - Backend usa DeepFace con modelo Facenet512
   - Genera embedding de 512 dimensiones
   - Verifica que no sea duplicado (threshold 0.15)
   - Guarda en tabla `faces` con `organization_id`

5. Al completar, el usuario ingresa:
   - Nombre completo
   - Se crea como `type: non_user` (visitante)
   - O se asocia con `user_id` si es usuario registrado

6. **Almacenamiento dual:**
   - ‚úÖ Backend: Embedding en MySQL (JSON con 512 valores)
   - ‚úÖ Local: 5 im√°genes guardadas para compatibilidad

### Flujo de Reconocimiento (Prueba en Tiempo Real)

1. Usuario abre Settings ‚Üí "Probar Reconocimiento Facial"
2. Se abre c√°mara frontal con preview
3. Usuario presiona "Capturar y Reconocer"
4. **Backend procesa:**
   - Imagen se env√≠a a `POST /api/v1/faces/recognize`
   - Extrae embedding con DeepFace/Facenet512
   - **Compara contra TODOS los rostros** de la organizaci√≥n
   - Calcula distancia coseno con cada embedding guardado
   - Filtra por threshold (default 0.4)
   - Retorna el mejor match (top_n=1)

5. **Respuesta muestra:**
   - ‚úÖ Reconocido: Nombre, tipo (Usuario/Visitante), confianza, face_id
   - ‚ùå No reconocido: Mensaje de que no hay coincidencia

### Backend - Modelo de Datos

**Tabla `faces`:**
```sql
- id (int, PK, auto_increment)
- organization_id (bigint, FK)
- user_id (bigint, FK, nullable) -- Si es registered_user
- type (enum: 'registered_user', 'non_user')
- embedding (json) -- Vector de 512 dimensiones [0.123, 0.456, ...]
- created_at (timestamp)
- updated_at (timestamp)
```

**Tabla `face_metadata` (para visitantes):**
```sql
- id (int, PK)
- face_id (int, FK)
- full_name (varchar 255)
- relationship (varchar 100, nullable)
- notes (text, nullable)
```

**Tipos de rostros:**
- `registered_user`: Tiene `user_id`, se obtiene nombre de tabla `users`
- `non_user`: Visitante, usa `face_metadata.full_name`

### Ver las Im√°genes Guardadas

Para verificar que las im√°genes se est√°n guardando:

```dart
// En cualquier parte de tu c√≥digo
final images = await FaceStorageService.getFaceImages('face_id_123');
print('Total im√°genes: ${images.length}');
for (var img in images) {
  print('Ruta: ${img.path}');
}
```

## üß™ C√≥mo Probar el Sistema

### 1. Registrar un Rostro

```bash
# Desde la app:
1. Settings ‚Üí Gestionar Rostros
2. Bot√≥n "Registrar Nuevo Rostro"
3. Seguir proceso de 5 capturas
4. Ingresar nombre: "Juan P√©rez"
5. Completar registro

# Logs esperados:
üì§ Enviando rostro al backend...
   URL: https://tu-api.com/api/v1/faces
   User ID: null
   Full Name: Juan P√©rez
üì° Respuesta: 201
‚úÖ Rostro registrado exitosamente
   Face ID: 123
   Type: non_user
```

### 2. Probar Reconocimiento

```bash
# Desde la app:
1. Settings ‚Üí Probar Reconocimiento Facial
2. Posicionar rostro frente a c√°mara
3. Bot√≥n "Capturar y Reconocer"

# Logs esperados si reconoce:
üîç Reconociendo rostro...
   Threshold: 0.4
   Top N: 1
üì° Respuesta: 200
‚úÖ Rostro reconocido!
   Confidence: 0.85
   Type: non_user

# Resultado en pantalla:
‚úÖ Rostro Reconocido!
üë§ Nombre: Juan P√©rez
üè∑Ô∏è Tipo: Visitante
üìä Confianza: 85.0%
üÜî Face ID: 123
```

### 3. Listar Rostros

```bash
# Desde la app:
1. Settings ‚Üí Gestionar Rostros
2. Ver lista de rostros registrados

# La pantalla carga desde backend autom√°ticamente
# useBackend = true en manage_faces_screen.dart
```

## üîß Par√°metros Configurables

### Threshold de Reconocimiento

En `test_face_recognition_screen.dart` l√≠nea 88:

```dart
final result = await FaceRecognitionApiService.recognizeFace(
  imagePath: image.path,
  threshold: 0.4,  // ‚Üê Ajustar aqu√≠
  topN: 1,
);
```

**Valores recomendados:**
- `0.3` - Muy estricto (solo coincidencias casi perfectas)
- `0.4` - Balanceado (default, recomendado)
- `0.5` - Permisivo (puede dar algunos falsos positivos)
- `0.6` - Muy permisivo (muchos falsos positivos)

### N√∫mero de Mejores Matches

```dart
threshold: 0.4,
topN: 3,  // Retorna los 3 mejores matches
```

## üîë Endpoints Utilizados

### POST /api/v1/faces - Registrar Rostro

**Request:**
```http
POST /api/v1/faces
Authorization: Bearer {token}
Content-Type: multipart/form-data

Body:
- image: File (imagen JPG/PNG)
- user_id: int (opcional, para usuarios registrados)
- full_name: string (requerido si user_id es null)
```

**Response 201:**
```json
{
  "id": 123,
  "organization_id": 5,
  "user_id": null,
  "type": "non_user",
  "created_at": "2025-11-17T12:00:00",
  "metadata": {
    "full_name": "Juan P√©rez"
  }
}
```

### POST /api/v1/faces/recognize - Reconocer Rostro

**Request:**
```http
POST /api/v1/faces/recognize
Authorization: Bearer {token}
Content-Type: multipart/form-data

Body:
- image: File
- threshold: float (default 0.4)
- top_n: int (default 1)
```

**Response 200 (Match encontrado):**
```json
{
  "match_found": true,
  "confidence": 0.85,
  "face": {
    "id": 123,
    "type": "non_user",
    "metadata": {
      "full_name": "Juan P√©rez"
    }
  }
}
```

**Response 200 (No match):**
```json
{
  "match_found": false,
  "message": "No se encontr√≥ ninguna coincidencia"
}
```

### GET /api/v1/faces - Listar Rostros

**Request:**
```http
GET /api/v1/faces?type=all&page=1&limit=20
Authorization: Bearer {token}
```

**Query params:**
- `type`: "all", "users", "non_users"
- `search`: Buscar por nombre
- `page`: P√°gina (default 1)
- `limit`: Items por p√°gina (default 20)

**Response 200:**
```json
{
  "total": 5,
  "page": 1,
  "limit": 20,
  "data": [
    {
      "id": 123,
      "type": "non_user",
      "metadata": {"full_name": "Juan P√©rez"},
      "user": null
    }
  ]
}
```

## üêõ Troubleshooting

### Error: "El archivo debe ser una imagen"

**Causa:** Falta content-type en multipart upload

**Soluci√≥n:** Ya solucionado con `MediaType.parse(contentType)` en l√≠neas 96-101 y 221-226 de `face_recognition_api_service.dart`

### Error: "No hay sesi√≥n activa"

**Causa:** Token no encontrado o nombre incorrecto

**Soluci√≥n:** Token se guarda como `'api_access_token'` en SharedPreferences (ya corregido en l√≠nea 15)

### Error: Type mismatch - int vs String

**Causa:** Backend usa int para IDs, local usa String

**Soluci√≥n:** Ya manejado en `manage_faces_screen.dart` con conversiones apropiadas

### Rostro duplicado (409 Conflict)

**Causa:** Backend detect√≥ embedding muy similar (distancia < 0.15)

**Soluci√≥n:**
- Esto es esperado, previene duplicados
- Usuario puede eliminar rostro anterior e intentar de nuevo
- O ajustar threshold de duplicados en backend

## üöÄ Anteriormente: Integraci√≥n con Backend (YA COMPLETADO)

### ~~Opci√≥n 1: Env√≠o Inmediato a API~~ ‚úÖ IMPLEMENTADO

~~Cuando tengas tu backend listo, modifica `face_capture_screen.dart` l√≠nea 248:~~

**Estado actual:** Ya implementado en `face_capture_screen.dart`

```dart
// ANTES (actual):
await FaceService.registerFace(
  name: name,
  relationship: relationship,
  imageUrl: imagePaths.isNotEmpty ? imagePaths.first : 'no_image',
  processingResult: {...},
  savedImagePaths: imagePaths,
);

// DESPU√âS (con API):
// 1. Enviar im√°genes a la API
final apiResponse = await FaceApiService.uploadFaceImages(
  faceId: _currentFaceId!,
  name: name,
  relationship: relationship,
  imagePaths: imagePaths,
  authToken: 'tu_token_jwt', // Obt√©n del auth service
);

if (apiResponse['success']) {
  // 2. Guardar con embeddings del backend
  await FaceService.registerFace(
    name: name,
    relationship: relationship,
    imageUrl: imagePaths.first,
    processingResult: {
      'steps_completed': steps.length,
      'final_confidence': apiResponse['confidence'],
      'embeddings': apiResponse['embeddings'], // Vector del backend
      'face_id': _currentFaceId,
    },
    savedImagePaths: imagePaths,
  );
}
```

### Opci√≥n 2: Env√≠o por Lotes (Batch)

Si prefieres enviar m√∫ltiples rostros a la vez:

```dart
// Obtener todos los rostros pendientes de sincronizaci√≥n
final pendingFaces = await getPendingFacesForSync();

// Enviar en batch
for (final faceData in pendingFaces) {
  final images = await FaceStorageService.getFaceImages(faceData['face_id']);
  final paths = images.map((f) => f.path).toList();

  await FaceApiService.uploadFaceImages(
    faceId: faceData['face_id'],
    name: faceData['name'],
    relationship: faceData['relationship'],
    imagePaths: paths,
    authToken: yourAuthToken,
  );
}
```

## üéØ Alternativa: Captura de Video

Si prefieres enviar un video corto en lugar de 5 im√°genes:

### Paso 1: Agregar dependencia

Ya tienes `camera`, pero necesitar√°s tambi√©n `video_player` (ya incluido):

```yaml
dependencies:
  camera: ^0.10.5+5
  video_player: ^2.8.1  # ‚úÖ Ya lo tienes
```

### Paso 2: Crear servicio de video

```dart
// lib/services/video_capture_service.dart
import 'package:camera/camera.dart';

class VideoCaptureService {
  static Future<String> recordFaceVideo({
    required CameraController controller,
    required String faceId,
    int durationSeconds = 10,
  }) async {
    // Iniciar grabaci√≥n
    await controller.startVideoRecording();

    // Grabar por X segundos
    await Future.delayed(Duration(seconds: durationSeconds));

    // Detener y guardar
    final videoFile = await controller.stopVideoRecording();

    // Guardar en storage
    final savedPath = await FaceStorageService.saveVideoFile(
      videoFile: videoFile,
      faceId: faceId,
    );

    return savedPath;
  }
}
```

### Paso 3: Modificar face_capture_screen.dart

Reemplazar el m√©todo `_captureStep()` con:

```dart
Future<void> _captureVideo() async {
  setState(() => isProcessing = true);

  try {
    _showMessage('Grabando por 10 segundos...');

    final videoPath = await VideoCaptureService.recordFaceVideo(
      controller: _cameraController!,
      faceId: _currentFaceId!,
      durationSeconds: 10,
    );

    _showMessage('Video guardado exitosamente');

    // Enviar a API para extraer frames y embeddings
    final apiResponse = await FaceApiService.uploadFaceVideo(
      faceId: _currentFaceId!,
      videoPath: videoPath,
      authToken: yourToken,
    );

    if (apiResponse['success']) {
      await _completeRegistration();
    }
  } catch (e) {
    _showMessage('Error al grabar video: $e');
  }

  setState(() => isProcessing = false);
}
```

## üîß M√©todos √ötiles del Storage Service

### Obtener espacio usado

```dart
final sizeBytes = await FaceStorageService.getTotalStorageSize();
final sizeFormatted = FaceStorageService.formatStorageSize(sizeBytes);
print('Espacio usado: $sizeFormatted'); // "2.5 MB"
```

### Eliminar rostro

```dart
await FaceStorageService.deleteFaceImages('face_id_123');
```

### Limpiar im√°genes antiguas

```dart
// Elimina im√°genes de hace m√°s de 30 d√≠as
await FaceStorageService.cleanupOldImages(daysOld: 30);
```

## üì° Estructura de la API Backend (Recomendada)

### Endpoint: Registrar Rostro

```
POST /api/faces
Content-Type: multipart/form-data
Authorization: Bearer {token}

Body:
- face_id: string
- name: string
- relationship: string
- images: File[] (array de im√°genes)
- captured_at: DateTime
```

**Respuesta esperada:**

```json
{
  "success": true,
  "face_id": "1234567890",
  "embeddings": [0.123, 0.456, ..., 0.789],
  "confidence": 0.95,
  "message": "Rostro procesado correctamente"
}
```

### Endpoint: Verificar Rostro

```
POST /api/faces/verify
Content-Type: multipart/form-data
Authorization: Bearer {token}

Body:
- image: File (imagen capturada)
```

**Respuesta esperada:**

```json
{
  "recognized": true,
  "face_id": "1234567890",
  "name": "Juan P√©rez",
  "relationship": "Familiar",
  "confidence": 0.92,
  "similarity_score": 0.88
}
```

## üß™ Testing

### Verificar que las im√°genes se guardan:

```dart
// En face_capture_screen, despu√©s de capturar
final images = await FaceStorageService.getFaceImages(_currentFaceId!);
print('‚úÖ Im√°genes guardadas: ${images.length}');
for (var img in images) {
  final exists = await img.exists();
  final size = await img.length();
  print('üìÅ ${img.path}: $size bytes, exists: $exists');
}
```

### Ver logs en consola:

Cuando captures un rostro, ver√°s:

```
‚úÖ Imagen guardada en: /data/.../face_123_step1_1234567890.jpg
‚úÖ Imagen guardada en: /data/.../face_123_step2_1234567891.jpg
...
üì∏ Total de im√°genes capturadas: 5
üìÇ Ubicaci√≥n: /data/.../registered_faces/face_123/
üì¶ Datos preparados para API:
   - Face ID: face_123
   - Nombre: Juan P√©rez
   - Im√°genes: 5
```

## ‚ö†Ô∏è Consideraciones Importantes

### 1. Privacidad y Seguridad
- Las im√°genes se guardan en el almacenamiento privado de la app
- Solo tu app puede acceder a ellas
- Considera encriptar las im√°genes si es informaci√≥n sensible

### 2. Espacio en Disco
- Cada imagen ocupa ~500KB - 2MB
- 5 im√°genes por rostro = ~5-10MB
- Con 5 rostros = ~25-50MB
- Implementa limpieza peri√≥dica

### 3. Permisos
Ya tienes configurado `permission_handler`, verifica en:
- **Android**: `AndroidManifest.xml`
- **iOS**: `Info.plist`

```xml
<!-- Android -->
<uses-permission android:name="android.permission.CAMERA"/>
<uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE"/>
```

```xml
<!-- iOS -->
<key>NSCameraUsageDescription</key>
<string>Necesitamos acceso a la c√°mara para registro facial</string>
```

## üé® Personalizaci√≥n

### Cambiar n√∫mero de pasos de captura

En `face_capture_screen.dart` l√≠nea 34:

```dart
final List<String> steps = [
  'Posiciona tu rostro en el centro',
  'Gira ligeramente hacia la izquierda',
  'Gira ligeramente hacia la derecha',
  // Agrega o quita pasos aqu√≠
];
```

### Cambiar calidad de imagen

En `face_capture_screen.dart` l√≠nea 112:

```dart
_cameraController = CameraController(
  frontCamera,
  ResolutionPreset.high,  // Cambiar: low, medium, high, veryHigh
  enableAudio: false,
);
```

## üìû Soporte

Si necesitas ayuda con:
- Integraci√≥n con tu backend espec√≠fico
- Procesamiento local de embeddings
- Optimizaci√≥n de almacenamiento
- Implementaci√≥n de video capture

Solo pregunta y te ayudo con el c√≥digo espec√≠fico.

---

**Estado actual:** ‚úÖ Almacenamiento local funcional
**Pr√≥ximo paso:** üîÑ Integraci√≥n con API de backend
**Alternativa:** üé• Captura de video (c√≥digo de ejemplo incluido arriba)
